%last edited 21.01.2015
\documentclass[11pt,reqno]{amsart}
\usepackage{amsmath,epsfig,graphicx,color}
%\usepackage[english,ngerman]{babel}
%\usepackage[latin1]{inputenc}
\usepackage{ifthen}
\usepackage{dsfont}
\usepackage{shadethm}
\usepackage{framed}
%\usepackage{pstricks}
%\usepackage{graphics}
%\usepackage{tocbibind}
%\usepackage{showkeys}
%\usepackage{units}
\usepackage{amssymb,latexsym}
%\usepackage{amsfonts}
%\usepackage{makeidx,showidx}
%\usepackage[sc]{mathpazo}
%\linespread{1.05}

\usepackage[backref=page]{hyperref}
\hypersetup{
%linktoc=page,
%bookmarks=true, % show bookmarks bar?
%unicode=false, % non-Latin characters in Acrobat? bookmarks
%pdftoolbar=true, % show Acrobat? toolbar?
%pdfmenubar=true, % show Acrobat? menu?
%pdffitwindow=true, % window fit to page when opened
%pdfstartview={FitH}, % fits the width of the page to the window
pdftitle={Paper}, % title
pdfauthor={Johannes Heiny}, % author
pdfsubject={Title}, % subject of the document
%pdfcreator={Creator}, % creator of the document
%pvdfproducer={Producer}, % producer of the document
pdfkeywords={multivariate regular variation} , % list of keywords
%pdfnewwindow=true, % links in new window
%colorlinks=true, % false: boxed links; true: colored links
%linkcolor=blue, % color of internal links
%citecolor=blue, % color of links to bibliography
%filecolor=blue, % color of file links
%urlcolor=blue, % color of external links
urlcolor=black, 
  menucolor=black, 
  citecolor=black, 
  anchorcolor=black, 
  filecolor=black, 
  linkcolor=black, 
  colorlinks=true,
}

\textwidth 6.50in
\topmargin -0.50in
\oddsidemargin 0in
\evensidemargin 0in
\textheight 9.00in
%\pagestyle{plain}

\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\1}{\mathds{1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Fo}{\bar{F}}
\renewcommand{\b}[1]{\boldsymbol{#1}}
\newcommand{\Rq}{\mkern 1.5mu\overline{\mkern-1.5mu\R\mkern-3.0mu}\mkern 1.5mu}
\newcommand{\Frechet}{Fr\'{e}chet }
\renewcommand{\Finv}{F^{\gets}}
\DeclareMathOperator{\e}{e}
\newcommand{\inv}[1]{#1^{\gets}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\y}{\boldsymbol{y}}
\newcommand{\X}{\boldsymbol{X}}
\newcommand{\Y}{\boldsymbol{Y}}
\newcommand{\0}{\boldsymbol{0}}
\newcommand{\dint}{\,\mathrm{d}}
\newcommand{\mB}{\mathcal{B}}
\newcommand{\norm}[1]{\|#1\|}
\newcommand{\twonorm}[1]{\|#1\|_2}
\newcommand{\inftynorm}[1]{\|#1\|_\infty}
\newcommand{\vep}{\varepsilon}


%von Schmock
\newcommand{\4}{\mathchoice{\mskip1.5mu}{\mskip1.5mu}{}{}}
\newcommand{\5}{\mathchoice{\mskip-1.5mu}{\mskip-1.5mu}{}{}}
\newcommand{\2}{\penalty250\mskip\thickmuskip\mskip-\thinmuskip} % after comma

\newcommand{\levy}{L\'evy}
\newcommand{\slln}{strong law of large numbers}
\newcommand{\clt}{central limit theorem}
\newcommand{\sde}{stochastic differential equation}
\newcommand{\It}{It\^o}
\newcommand{\sta}{St\u aric\u a}
\newcommand{\ex}{{\rm e}\,}

\def\theequation{\thesection.\arabic{equation}}
\def\tag{\refstepcounter{equation}\leqno }
\def\neqno{\refstepcounter{equation}\leqno(\thesection.\arabic{equation})}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{figur}[lemma]{Figure}
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{example}[lemma]{Example}
\newtheorem{exercise}[lemma]{Exercise}
\newtheorem{remark}[lemma]{Remark}
\newtheorem{fig}[lemma]{Figure}
\newtheorem{tab}[lemma]{Table}

\newcommand{\cid}{\stackrel{d}{\rightarrow}}
\newcommand{\cip}{\stackrel{\P}{\rightarrow}}

\newcommand{\var}{{\rm var}}
\newcommand{\med}{{\rm med}}
\newcommand{\cov}{{\rm cov}}
\newcommand{\corr}{{\rm corr}}
\newcommand{\as}{{\rm a.s.}}
\newcommand{\io}{{\rm i.o.}}



\newcommand{\beao}{\begin{eqnarray*}}
\newcommand{\eeao}{\end{eqnarray*}\noindent}

\newcommand{\beam}{\begin{eqnarray}}
\newcommand{\eeam}{\end{eqnarray}\noindent}

\newcommand{\beqq}{\begin{equation}}
\newcommand{\eeqq}{\end{equation}\noindent}

\newcommand{\cadlag}{c\`adl\`ag}

%\newcommand{\vague}{\stackrel{\lower0.2ex\hbox{$\scriptscriptstyle\it{v} $}}{\rightarrow}}
%\newcommand{\weak}{\stackrel{\lower0.2ex\hbox{$\scriptscriptstyle\it{w} $}}{\rightarrow}}
%\newcommand{\what}{\stackrel{\lower0.2ex\hbox{$\scriptscriptstyle\it{\hat{w}} $}}{\rightarrow}}

\newcommand{\bdis}{\begin{displaymath}}
\newcommand{\edis}{\end{displaymath}\noindent}

%--------------------------------------------------------------------------------------------
\begin{document}
\today
\bibliographystyle{plain}
\title[Toolbox]{Toolbox}
%\author[Johannes Heiny]{Johannes Heiny}
%\address{Department  of Mathematics,
%University of Copenhagen,
%Universitetsparken 5,
%DK-2100 Copenhagen,
%Denmark}
%\email{johannes.heiny@math.ku.dk}
\begin{abstract}
This is a collection of probability inequalities and other useful results. First some very basic inequalities, then results connected to regular variation and finally the techniques used to prove the results for our particular matrix structure. 
\end{abstract}
%\keywords{enter keywords}
%\subjclass{Primary 60B20; Secondary 60F05 60F10 60G10 60G55 60G70}

\maketitle

\section{Basic Inequalities}\setcounter{equation}{0}

\begin{itemize}

\item For any $X,Y$ and $\epsilon>0$:
\begin{equation*}
\P(X+Y>\epsilon) \leq \P(X>\epsilon/2)+\P(Y>\epsilon/2).
\end{equation*}
\item $\P(X\1_A >\epsilon)\leq \P(A)$.
\item For $X\geq 0$ we have $\P(\sum_i X_i \1_{A_i} >\epsilon)\leq \P(\bigcup_i A_i)\leq \sum_i\P( A_i)$.

\item for $\1_{\{\sum Z^2\leq a_{np}^2\}}$ use Markov inequality
\item Markov inequality. $X$ nonnegative integrable rv.
\begin{equation*}
\P(X\geq a) \leq \frac{\E[X]}{a}.
\end{equation*}

\item Chebyschev inequality. $X$ nonnegative integrable rv.
\begin{equation*}
\P(|X-\E[X]|\geq a) \leq \frac{\Var(X)}{a^2}.
\end{equation*}

\item Kolmogorov inequality. $X_1, \ldots, X_n$ independent, zero mean, finite variances. $S_k$ partial sum.
\begin{equation*}
\P\left(\max_{1\leq k\leq n} |S_k| \geq \lambda\right) \leq \frac{1}{\lambda^2} \sum_{k=1}^n \Var(X_k).
\end{equation*}

\item Etemadi inequality. $X_1, \ldots, X_n$ independent real valued. $\lambda\geq 0$.
\begin{equation*}
\P\left(\max_{1\leq k\leq n} |S_k| \geq 3\lambda\right) \leq 3 \max_{1\leq k\leq n}\P\left( |S_k| \geq \lambda\right).
\end{equation*}

\item Bernstein inequality. $X_1, \ldots, X_n$ independent real valued, zero mean. Suppose $|X_i|\leq M, t>0$.
\begin{equation*}
\P\left(\sum_{i=1}^n X_i >t \right) \leq \exp \left( -\frac{t^2}{2(\sum \E[X_i^2] +Mt/3)}\right).
\end{equation*}

\item H\"older inequality. Assume that $p$ and $q$ are in the open interval $(1,\infty)$ with $1/p + 1/q = 1$. We have
\begin{equation*}
\sum_{k=1}^\infty |x_k y_k| \leq \left(\sum_{k=1}^\infty |x_k|^p \right)^{1/p} \left(\sum_{k=1}^\infty |y_k|^q \right)^{1/q}
\end{equation*}

\item Lyapunov inequality: Let $1 \le r  \le s$ and $E[|X|^s] <\infty$. Then
\begin{equation*}
E[|X|^r]^{1/r} \le E[|X|^s]^{1/s}.
\end{equation*}

\item Minkowski. $r\ge 1$.
\begin{equation*}
E[|X+Y|^r]^{1/r}\le E[|X|^r]^{1/r}+E[|Y|^r]^{1/r}
\end{equation*}

\item Rosenthal. If $(X_i)$ is a sequence of independent rvs with expectation zero, then for any $r\ge 2$,
\begin{equation*}
\E \Big[  \Big|\sum_{i=1}^n X_i \Big|^r \Big] \le C_r \Big( \Big(\sum_{i=1}^n \E[X_i^2] \Big)^{r/2} + \sum_{i=1}^n E[|X_i|^r] \Big).
\end{equation*}
%
%\item
\end{itemize}

%---------------------------------------------------------------------------------------
\section{Matrix norms}

Let $A$ be an $m\times n$ matrix, and $p,q \ge 1$. The $L_{p,q}$ norm is defined as
\begin{equation*}
\| A\|_{p,q} = \Big[ \sum_{j=1}^n \Big( \sum_{i=1}^m |a_{ij}|^p \Big)^{q/p} \Big]^{1/q}.
\end{equation*}


%---------------------------------------------------------------------------------------
\section{Other Formulas}

Assume $X\geq 0$ and $g$ increasing differentiable with $g(0)=0$, then:
\begin{equation*}
\E[g(x)]= [-g(t) \Fo(t)]_0^\infty - \int_0^\infty \Fo(t) d(-g(t))=\int_0^\infty g'(t) \Fo(t) dt.
\end{equation*}

\section{Regular Variation}

\begin{itemize}
\item Let $\ell$ be slowly varying at infinity. Then for all $\epsilon>0$,
\begin{equation*}
\begin{split}
\lim_{x\to \infty} x^{\epsilon}\ell(x)&= \infty,\\
\lim_{x\to \infty} x^{-\epsilon}\ell(x)&= 0,\\
\lim_{x\to \infty} \frac{\log\ell(x)}{\log x}&= 0.
\end{split}
\end{equation*}


\item {\bf Potter's bounds.} $f\in \text{RV}_\infty (\alpha)$. For any $\epsilon>0$ and $C>1$, there esxists $x_0$ such that for all $y\geq x\geq x_0$,
\begin{equation*}
C^{-1} (y/x)^{\alpha-\epsilon}\leq \frac{f(y)}{f(x)} \leq C (y/x)^{\alpha+\epsilon}
\end{equation*}

\item $\P(\max_{1\leq i \leq k} X_i)\sim k\Fo(x), \quad x\to \infty$.
\item Maxima and sums of non-negative rvs:

$M_n/S_n \to 1$ in probability iff $\Fo$ is slowly varying at infinity.

$M_n/S_n$ has a non degenerate distribution iff $\Fo$ is regularly varying with $\alpha \in (0,1)$.

\item If $\Fo$ is regularly varying, then for all $\epsilon>0$, there
exists a constant $C$ such that 
\begin{equation*}
1-F^{*n}(x) \leq C(1+\epsilon)^n \Fo (x).
\end{equation*}

\item {\bf Truncated Moments.} Assume $X$ is regularly varying with index $\alpha$. Then
\begin{equation*}
\begin{split}
\E[X^\beta \1_{\{X\leq x\}}] &\sim \frac{\alpha}{\beta -\alpha} x^\beta \Fo(x), \quad \beta>\alpha,\\
\E[X^\beta \1_{\{X > x\}}] &\sim \frac{\alpha}{\alpha-\beta} x^\beta \Fo(x), \quad \beta<\alpha.
\end{split}
\end{equation*}

\item Lemma for Breiman. Assume $X$ is regularly varying with index $\alpha$. Then
there exists a constant $C$ such that for any $x,y>0$,
\begin{equation*}
\frac{\P(yX>x)}{\P(X>x)}\leq C (1 \vee y)^{\alpha +\epsilon}.
\end{equation*}

\item {\bf Breiman.} $\P(AB>x) \sim \E[A^\alpha] \P(B>x)$.

\item By Karamata: Sequence $s_n\to \infty$, then
\begin{equation*}
\E[s_n^{-1}Z^2\1_{\{Z^2\leq s_n\}}]\leq c \P(Z^2> s_n).
\end{equation*}
\end{itemize}

\begin{theorem}[Classical Karamata]
$L$ slowly varying, locally bounded for in $[x_0,\infty)$ for some $x_0\geq 0$. Then
\begin{enumerate}
\item for $\rho >-1$,
\begin{equation*}
\int_{x_0}^x t^\rho L(t) dt \sim \frac{1}{\rho +1} x^{\rho+1} L(x), \quad x\to \infty,
\end{equation*}
\item for $\rho <-1$,
\begin{equation*}
\int_x^\infty t^\rho L(t) dt \sim -\frac{1}{\rho +1} x^{\rho+1} L(x), \quad x\to \infty.
\end{equation*}
\end{enumerate}
\end{theorem}

\begin{theorem}[Modified Karamata with $\alpha >0$.]
$\Fo(x)= x^{-\alpha} L(x)$. Then
\begin{enumerate}
\item for $\alpha \in (0,1)$,
\begin{equation*}
\int_{x_0}^x \Fo (t) dt \sim \frac{1}{1-\alpha} x \Fo(x), \quad x\to \infty,
\end{equation*}
\item for $\alpha >1$,
\begin{equation*}
\int_x^\infty \Fo (t) dt \sim \frac{1}{\alpha-1} x \Fo(x), \quad x\to \infty.
\end{equation*}
\end{enumerate}
\end{theorem}





We collect some useful results about regularly varying distributions. Let $\{Z_i\}$ be an iid sequence of regularly varying random variables, i.e.
\begin{equation*}
\begin{split}
\P(|Z_1|>x) &= x^{-\alpha} L(x)\\
\frac{\P(Z_1>x)}{\P(|Z_1|>x)}&\to p_+.
\end{split}
\end{equation*} 
Assume $\E[|Z_1|^\alpha]=\infty$ and define 
\begin{equation*}
\begin{split}
a_n &=\inf\{x: \P(|Z_1|>x) \leq \frac{1}{n} \},\\
b_n &=\inf\{x: \P(|Z_1Z_2|>x) \leq \frac{1}{n} \}.
\end{split}
\end{equation*} 
Then we get
\begin{equation*}
\begin{split}
\P(|Z_1Z_2|>x) &= x^{-\alpha} \tilde{L}(x),\\
\frac{\P(Z_1Z_2>x)}{\P(|Z_1Z_2|>x)} &\to p_+^2+(1-p_+)^2,\\
\lim_{x\to \infty}\frac{\P(|Z_1Z_2|>x)}{\P(|Z_1|>x)} &= \infty,\\
\lim_{n\to\infty} \frac{b_n}{a_n}&= \infty.
\end{split}
\end{equation*}

\begin{example}
If $\P(|Z_1|>x) \sim x^{-\alpha}$, then
\begin{equation*}
\begin{split}
\P(|Z_1Z_2|>x) &= x^{-\alpha} (1+\alpha \log x),\\
a_n &\sim n^{1/\alpha},\\
b_n &\sim (n \log n)^{1/\alpha}.
\end{split}
\end{equation*}
In particular $\frac{a_n^2}{b_n}\to \infty$. This shows that if we normalize $Z_1 Z_2$ by $a_n^2$ it will be negligible in probability. 
\end{example}

\begin{lemma}
$\alpha=1$ and $Z$ is regularly varying with index $\alpha$. Assume $\E[|Z|]=\infty$. The function
\begin{equation*}
L(x)=\frac{\E[|x^{-1} Z |\1_{\{|Z|\leq x\}}]}{\P(|Z|>x)},\quad x>0,
\end{equation*}
is slowly varying and converges to infinity, but
\begin{equation*}
\E[|x^{-1} Z |\1_{\{|Z|\leq x\}}]+\P(|Z|>x),\quad x>0,
\end{equation*}
decreases and is regularly varying with index $-1$.
\end{lemma}






%-------------------------------------------------------------------
\section{Point Processes}

\begin{remark}
Let $\{Y_{ni}\}_{i,n=1,\ldots,\infty}$ be an array of dependent identically distributed random variables. A standard set of sufficient conditions to guarantee that
\begin{equation*}
\sum_{i=1}^n \vep_{(i/n,Y_{ni})} \cid \sum_{i=1}^\infty \vep_{(t_i,j_i)}
\end{equation*}
for a PRM($\dint t \times \dint \nu$) is
\begin{itemize}
\item a mixing condition, f.i. $D^*$; or $m$-dependence.
\item a mean value condition 
\begin{equation*}
n \P(Y_{n1}\in \cdot)\stackrel{v}{\rightarrow}\nu.
\end{equation*}
\item And a condition to control the error in the small blocks large blocks approximation of the Laplace functional; for example function $g\leq 1$ and
\begin{equation*}
\lim_{k\to \infty} \limsup_{n\to \infty} n \sum_{i=2}^{[\frac{n}{k}]}\E[g(Y_{n1})g(Y_{ni})] =0.
\end{equation*}
\end{itemize}
\end{remark}














\end{document}